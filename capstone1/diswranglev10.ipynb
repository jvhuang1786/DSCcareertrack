{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas \n",
    "import pandas as pd\n",
    "#import numpy\n",
    "import numpy as np\n",
    "#import warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set iPython's max column width to 1000\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.float_format = '{:,.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in json file \n",
    "file = 'disresort2.json'\n",
    "df = pd.read_json(file,lines = True, orient= 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take columns for the sentiment analysis\n",
    "df = df[['text','id',\n",
    "          'lang','created_at',\n",
    "          'user','source','retweeted_status',\n",
    "          'extended_tweet', 'entities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out entities\n",
    "df['entities_hashtag'] = np.array([x['hashtags'] for x in df['entities']])\n",
    "\n",
    "df['entities_user_mentions'] = np.array([x['user_mentions'] for x in df['entities']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retweeted status nested dictionary \n",
    "df['rt_created_at'] = [d.get('created_at') if type(d) == dict else np.nan\n",
    "                        for d in df['retweeted_status']]\n",
    "df['rt_id'] =  [d.get('id') if type(d) == dict else np.nan\n",
    "                 for d in df['retweeted_status']]\n",
    "df['rt_text'] = [d.get('text') if type(d) == dict else np.nan\n",
    "                  for d in df['retweeted_status']]\n",
    "df['rt_source'] = [d.get('source') if type(d) == dict else np.nan\n",
    "                    for d in df['retweeted_status']]\n",
    "df['rt_user'] = [d.get('user') if type(d) == dict else np.nan\n",
    "                  for d in df['retweeted_status']]\n",
    "df['rt_retweet_count'] = [d.get('retweet_count') if type(d) == dict else np.nan\n",
    "                           for d in df['retweeted_status']]\n",
    "df['rt_extended_entities'] = [d.get('extended_entities') if type(d) == dict else np.nan\n",
    "                               for d in df['retweeted_status']]\n",
    "df['rt_entities'] = [d.get('entities') if type(d) == dict else np.nan\n",
    "                      for d in df['retweeted_status']]\n",
    "df['rt_favorite_count'] = [d.get('favorite_count') if type(d) == dict else np.nan\n",
    "                            for d in df['retweeted_status']]\n",
    "df['rt_lang'] = [d.get('lang') if type(d) == dict else np.nan\n",
    "                  for d in df['retweeted_status']]\n",
    "df['rt_user_mentions'] = [d.get('user_mentions') if type(d) == dict else np.nan\n",
    "                           for d in df['retweeted_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out extended Tweets\n",
    "df['ex_tw_full_text'] = [d.get('full_text') if type(d) == dict else np.nan\n",
    "                          for d in df['extended_tweet']]\n",
    "df['ex_tw_entities'] = [d.get('entities') if type(d) == dict else np.nan\n",
    "                         for d in df['extended_tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting dictionaries from user, nested dictionary\n",
    "df['user_id'] = np.array([x['id'] for x in df['user']])\n",
    "df['user_screen_name'] = np.array([x['screen_name'] for x in df['user']])\n",
    "df['user_location'] = np.array([x['location'] for x in df['user']])\n",
    "df['user_description'] = np.array([x['description'] for x in df['user']])\n",
    "df['user_fol_count'] = np.array([x['followers_count'] for x in df['user']])\n",
    "df['user_fr_count'] = np.array([x['friends_count'] for x in df['user']])\n",
    "df['user_fav_count'] = np.array([x['favourites_count'] for x in df['user']])\n",
    "df['user_status_count'] = np.array([x['statuses_count'] for x in df['user']])\n",
    "df['user_created_at'] = np.array([x['created_at'] for x in df['user']])\n",
    "df['user_listed_count'] = np.array([x['listed_count'] for x in df['user']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out hashtags and user mentions from entities\n",
    "df['entities_hashtags'] = [d.get('hashtags') if type(d) == dict\n",
    "                          else np.nan for d in df['entities']]\n",
    "df['entities_user_mentions'] = [d.get('user_mentions') if type(d) == dict\n",
    "                          else np.nan for d in df['entities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out hashtags from entities_hashtags\n",
    "df['entities_hashtags'] = df['entities_hashtags'].apply(lambda y: '' if len(y) == 0 else y)\n",
    "\n",
    "\n",
    "test = df['entities_hashtags'].apply(pd.Series)\n",
    "\n",
    "one = test[0].apply(pd.Series)\n",
    "two = test[1].apply(pd.Series)\n",
    "three = test[2].apply(pd.Series)\n",
    "four = test[3].apply(pd.Series)\n",
    "five = test[4].apply(pd.Series)\n",
    "six = test[5].apply(pd.Series)\n",
    "seven = test[6].apply(pd.Series)\n",
    "eight = test[7].apply(pd.Series)\n",
    "nine = test[8].apply(pd.Series)\n",
    "ten = test[9].apply(pd.Series)\n",
    "eleven = test[10].apply(pd.Series)\n",
    "\n",
    "one = pd.DataFrame(one['text'])\n",
    "two = pd.DataFrame(two['text'])\n",
    "two = two.rename(columns={'text': 'text1'})\n",
    "three = pd.DataFrame(three['text'])\n",
    "three = three.rename(columns={'text': 'text2'})\n",
    "four = pd.DataFrame(four['text'])\n",
    "four = four.rename(columns={'text': 'text3'})\n",
    "\n",
    "\n",
    "five = pd.DataFrame(five['text'])\n",
    "five= five.rename(columns={'text': 'text4'})\n",
    "\n",
    "\n",
    "six = pd.DataFrame(six['text'])\n",
    "six= six.rename(columns={'text': 'text5'})\n",
    "\n",
    "\n",
    "seven = pd.DataFrame(seven['text'])\n",
    "seven= seven.rename(columns={'text': 'text6'})\n",
    "\n",
    "\n",
    "eight = pd.DataFrame(eight['text'])\n",
    "eight = eight.rename(columns={'text': 'text7'})\n",
    "\n",
    "\n",
    "nine = pd.DataFrame(nine['text'])\n",
    "nine= nine.rename(columns={'text': 'text8'})\n",
    "\n",
    "\n",
    "ten = pd.DataFrame(ten['text'])\n",
    "ten= ten.rename(columns={'text': 'text9'})\n",
    "\n",
    "eleven = pd.DataFrame(eleven['text'])\n",
    "eleven= eleven.rename(columns={'text': 'text10'})\n",
    "\n",
    "df_list = [one, two, three,four,five,six,seven,eight,nine,ten,eleven]\n",
    "\n",
    "data12 = pd.concat(df_list, axis=1) # join='inner'\n",
    "data12= data12[data12.columns[:]].apply(\n",
    "    lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "df['entities_hashtags'] = data12\n",
    "df['entities_hashtags'] = [x.split() for x in df['entities_hashtags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now do the same for entities_user_mentions to get the @ out 8 columns\n",
    "test1 = df['entities_user_mentions'].apply(pd.Series)\n",
    "one1 = test1[0].apply(pd.Series)\n",
    "one1 = one1.drop(columns = {0,'id_str', 'indices'})\n",
    "\n",
    "two1 = test1[1].apply(pd.Series)\n",
    "two1 = two1.drop(columns = {0,'id_str', 'indices'})\n",
    "two1 = two1.rename(columns={'id': 'id1', 'screen_name': 'screen_name1','name': 'name1'})\n",
    "two1 = pd.DataFrame(two1)\n",
    "\n",
    "three1 = test1[2].apply(pd.Series)\n",
    "three1 = three1.drop(columns = {0,'id_str', 'indices'})\n",
    "three1 = three1.rename(columns={'id': 'id2', 'screen_name': 'screen_name2','name': 'name2'})\n",
    "three1 = pd.DataFrame(three1)\n",
    "\n",
    "four1 = test1[3].apply(pd.Series)\n",
    "four1 = four1.drop(columns = {0,'id_str', 'indices'})\n",
    "four1 = four1.rename(columns={'id': 'id3', 'screen_name': 'screen_name3','name': 'name3'})\n",
    "four1 = pd.DataFrame(four1)\n",
    "\n",
    "five1 = test1[4].apply(pd.Series)\n",
    "five1 = five1.drop(columns = {0,'id_str','indices'})\n",
    "five1 = five1.rename(columns={'id': 'id4', 'screen_name': 'screen_name4','name': 'name4'})\n",
    "five1 = pd.DataFrame(five1)\n",
    "\n",
    "six1 = test1[5].apply(pd.Series)\n",
    "six1 = six1.drop(columns = {0, 'id_str', 'indices'})\n",
    "six1 = six1.rename(columns={'id': 'id5', 'screen_name': 'screen_name5','name': 'name5'})\n",
    "six1 = pd.DataFrame(six1)\n",
    "\n",
    "seven1 = test1[6].apply(pd.Series)\n",
    "seven1 = seven1.drop(columns = {0,'id_str','indices'})\n",
    "seven1 = seven1.rename(columns={'id': 'id6', 'screen_name': 'screen_name6','name': 'name6'})\n",
    "seven1 = pd.DataFrame(seven1)\n",
    "\n",
    "eight1 = test1[7].apply(pd.Series)\n",
    "eight1 = eight1.drop(columns = {0,'id_str','indices'})\n",
    "eight1 = eight1.rename(columns={'id': 'id7', 'screen_name': 'screen_name7','name': 'name7'})\n",
    "eight1 = pd.DataFrame(eight1)\n",
    "\n",
    "df2_list = [one1, two1, three1,four1,five1,six1,seven1,eight1]\n",
    "\n",
    "data13 = pd.concat(df2_list, axis=1) # join='inner'\n",
    "comb_id = (data13[\"id\"].map(str) + ' ' + data13[\"id1\"].map(str) + ' ' +\n",
    "           data13[\"id2\"].map(str) + ' ' + data13[\"id3\"].map(str) +\n",
    "           ' ' + data13[\"id4\"].map(str) + ' ' + data13[\"id5\"].map(str) +\n",
    "           ' ' + data13[\"id6\"].map(str) + ' ' + data13[\"id7\"].map(str))\n",
    "comb_name = (data13[\"name\"].map(str) + ' ' + data13[\"name1\"].map(str) + ' ' +\n",
    "           data13[\"name2\"].map(str) + ' ' + data13[\"name3\"].map(str) +\n",
    "           ' ' + data13[\"name4\"].map(str) + ' ' + data13[\"name5\"].map(str) +\n",
    "           ' ' + data13[\"name6\"].map(str) + ' ' + data13[\"name7\"].map(str))\n",
    "comb_screen_name = (data13[\"screen_name\"].map(str) + ' ' + data13[\"screen_name1\"].map(str) + ' ' +\n",
    "           data13[\"screen_name2\"].map(str) + ' ' + data13[\"screen_name3\"].map(str) +\n",
    "           ' ' + data13[\"screen_name\"].map(str) + ' ' + data13[\"screen_name5\"].map(str) +\n",
    "           ' ' + data13[\"screen_name6\"].map(str) + ' ' + data13[\"screen_name7\"].map(str))\n",
    "df3_list = [comb_id,comb_name,comb_screen_name]\n",
    "data14 = pd.concat(df3_list, axis= 1)\n",
    "data14.columns = ['id', 'name', 'screen_name']\n",
    "data14['id'] = [x.split() for x in data14['id']]\n",
    "data14['name'] = [x.split() for x in data14['name']]\n",
    "data14['screen_name'] = [x.split() for x in data14['screen_name']]\n",
    "data14.columns = ['entities_user_mentions_id', 'entities_user_mentions_name', 'entities_user_mentions_screen_name']\n",
    "df[['entities_user_mentions_id', 'entities_user_mentions_name', 'entities_user_mentions_screen_name']] = data14\n",
    "\n",
    "df['entities_user_mentions_id'] = df['entities_user_mentions_id'].apply(lambda x: [i for i in x if str(i) != \"nan\"])\n",
    "df['entities_user_mentions_name'] = df['entities_user_mentions_name'].apply(lambda x: [i for i in x if str(i) != \"nan\"])\n",
    "df['entities_user_mentions_screen_name'] = df['entities_user_mentions_screen_name'].apply(lambda x: [i for i in x if str(i) != \"nan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get nested dictionary within rt_user \n",
    "\n",
    "df['rt_user_id'] = [d.get('id') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_name'] = [d.get('name') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_screen_name'] = [d.get('screen_name') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_location'] = [d.get('location') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_follower_count'] = [d.get('followers_count') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_friends_count'] = [d.get('friends_count') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_listed_count'] = [d.get('listed_count') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_listed_count'] = [d.get('listed_count') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_favorites_count'] = [d.get('favourites_count') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_statuses_count'] = [d.get('statuses_count') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_created_at'] = [d.get('created_at') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]\n",
    "df['rt_user_description'] = [d.get('description') if type(d) == dict\n",
    "                          else np.nan for d in df['rt_user']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up the source\n",
    "from bs4 import BeautifulSoup\n",
    "df['source'] = [BeautifulSoup(text).get_text() for text in df['source']]\n",
    "#clean rt_source\n",
    "df['rt_source']= df['rt_source'].replace(np.nan, '')\n",
    "df['rt_source'] = [BeautifulSoup(text).get_text() if text != np.nan\n",
    "                    else np.nan for text in df['rt_source']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extended_tweets\n",
    "df['ex_tw_entities_hashtags'] = [d.get('hashtags') if type(d) == dict\n",
    "                          else np.nan for d in df['ex_tw_entities']]\n",
    "df['ex_tw_entities_user_mentions'] = [d.get('user_mentions') if type(d) == dict\n",
    "                          else np.nan for d in df['ex_tw_entities']]\n",
    "\n",
    "#ex_tw_entities_hashtags 15 columns\n",
    "test3 = df['ex_tw_entities_hashtags'].apply(pd.Series)\n",
    "\n",
    "one_ = test3[0].apply(pd.Series)\n",
    "one_ = one_.drop(columns = {0,'indices'})\n",
    "\n",
    "\n",
    "two_ = test3[1].apply(pd.Series)\n",
    "two_ = two_.drop(columns = {0,'indices'})\n",
    "two_ = two_.rename(columns={'text':'text1'})\n",
    "two_ = pd.DataFrame(two_)\n",
    "\n",
    "three_ = test3[2].apply(pd.Series)\n",
    "three_ = three_.drop(columns = {0,'indices'})\n",
    "three_= three_.rename(columns={'text':'text2'})\n",
    "three_= pd.DataFrame(three_)\n",
    "\n",
    "four_ = test3[3].apply(pd.Series)\n",
    "four_  = four_.drop(columns = {0,'indices'})\n",
    "four_ = four_.rename(columns={'text':'text3'})\n",
    "four_ = pd.DataFrame(four_ )\n",
    "\n",
    "five_ = test3[4].apply(pd.Series)\n",
    "five_  = five_.drop(columns = {0,'indices'})\n",
    "five_  = five_.rename(columns={'text':'text4'})\n",
    "five_  = pd.DataFrame(five_ )\n",
    "\n",
    "six_ = test3[5].apply(pd.Series)\n",
    "six_  = six_.drop(columns = {0,'indices'})\n",
    "six_  = six_.rename(columns={'text':'text5'})\n",
    "six_  = pd.DataFrame(six_ )\n",
    "\n",
    "sev_ = test3[6].apply(pd.Series)\n",
    "sev_  = sev_.drop(columns = {0,'indices'})\n",
    "sev_  = sev_.rename(columns={'text':'text6'})\n",
    "sev_  = pd.DataFrame(sev_)\n",
    "\n",
    "eig_= test3[7].apply(pd.Series)\n",
    "eig_= eig_.drop(columns = {0,'indices'})\n",
    "eig_= eig_.rename(columns={'text':'text7'})\n",
    "eig_ = pd.DataFrame(eig_)\n",
    "\n",
    "nine_= test3[8].apply(pd.Series)\n",
    "nine_= nine_.drop(columns = {0,'indices'})\n",
    "nine_= nine_.rename(columns={'text':'text8'})\n",
    "nine_ = pd.DataFrame(nine_)\n",
    "\n",
    "\n",
    "ten_= test3[9].apply(pd.Series)\n",
    "ten_= ten_.drop(columns = {0,'indices'})\n",
    "ten_= ten_.rename(columns={'text':'text9'})\n",
    "ten_ = pd.DataFrame(ten_)\n",
    "\n",
    "eleven_= test3[10].apply(pd.Series)\n",
    "eleven_= eleven_.drop(columns = {0,'indices'})\n",
    "eleven_= eleven_.rename(columns={'text':'text10'})\n",
    "eleven_= pd.DataFrame(eleven_)\n",
    "\n",
    "\n",
    "twel_= test3[11].apply(pd.Series)\n",
    "twel_= twel_.drop(columns = {0,'indices'})\n",
    "twel_= twel_.rename(columns={'text':'text11'})\n",
    "twel_= pd.DataFrame(twel_)\n",
    "\n",
    "\n",
    "thir_= test3[12].apply(pd.Series)\n",
    "thir_= thir_.drop(columns = {0,'indices'})\n",
    "thir_= thir_.rename(columns={'text':'text12'})\n",
    "thir_= pd.DataFrame(thir_)\n",
    "\n",
    "fourt = test3[13].apply(pd.Series)\n",
    "fourt = fourt.drop(columns = {0,'indices'})\n",
    "fourt = fourt.rename(columns={'text':'text13'})\n",
    "fourt = pd.DataFrame(fourt)\n",
    "\n",
    "\n",
    "fift = test3[14].apply(pd.Series)\n",
    "fift =fift.drop(columns = {0,'indices'})\n",
    "fift =fift.rename(columns={'text':'text14'})\n",
    "fift = pd.DataFrame(fift)\n",
    "\n",
    "df4_list = [one_, two_, three_,four_,five_,six_,sev_,eig_,\n",
    "            nine_,ten_,eleven_,twel_,thir_,fourt,fift]\n",
    "\n",
    "data21 = pd.concat(df_list, axis=1)\n",
    "data21= data21[data21.columns[:]].apply(\n",
    "    lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df['ex_tw_entities_hashtags'] = data21\n",
    "df['ex_tw_entities_hashtags'] = [x.split() for x in df['ex_tw_entities_hashtags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the date time column\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['rt_created_at'] = pd.to_datetime(df['rt_created_at'])\n",
    "df['rt_user_created_at'] = pd.to_datetime(df['rt_user_created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign text length to count len of each text line \n",
    "df = df.assign(text_length=df['text'].apply(len))\n",
    "df['rt_text'] = df['rt_text'].replace(np.nan,'')\n",
    "df['rt_text_length'] = [len(x) if x != '' else '' for x in df['rt_text']]\n",
    "df['ex_tw_full_text'] = df['ex_tw_full_text'].replace(np.nan,'')\n",
    "df['ex_tw_full_text_length'] = [len(x) if x != '' else '' for x in df['ex_tw_full_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unecssary columns\n",
    "df = df.drop(columns = {'rt_entities', 'entities_user_mentions',\n",
    "                          'ex_tw_entities_user_mentions', 'rt_user',\n",
    "                          'rt_extended_entities','rt_user_mentions',\n",
    "                          'entities_hashtag', 'retweeted_status', \n",
    "                        'extended_tweet', 'user', 'entities'\n",
    "                       'ex_tw_entities'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving cleand data as a csv file \n",
    "df.to_csv('cleaned_sample_dis.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
